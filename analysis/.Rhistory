MeanSimilarity = mean(ChunkSimilarity))
hsizeB <- a %>%
filter(Day < -1, RuminationFrequency == 0) %>%
group_by(Run, I, PTES, NumAttributes, RuminationFrequency, W, gamma) %>%
summarize(H = h_entropy(MemoryEntropy) - HPre,
HippocampusDecrease = 100*(mean(MemoryEntropy)/H1 - 1))
hsizePre <- inner_join(hsizeA, hsizeB)
ggplot(filter(hsizePre, I != 1),
aes(y=MeanTraumatic, x=HippocampusDecrease, col = I)) +
facet_wrap(~ W, scales="free_x", labeller = label_both) +
geom_point(alpha = .1, size=1) +
scale_color_brewer(palette="Dark2") +
geom_smooth(method = "lm", formula = y ~ x, aes(col=I), fill="white",
fullrange= T) + # theme_pander() +
xlab("Percentage Difference in Hippocampus Volume Before PTE") +
ylab("Relative Frequency of Traumatic Memory Intrusion (Day 50-60)") +
ggtitle("Correlation Between Initial Hippocampal Volume \nand Symptom Severity After PTE") +
theme_pander() +
theme(legend.position = "bottom") #+
ggsave("figure5.png")
W4 <- filter(hsizePre, W==4)
W8 <- filter(hsizePre, W==8)
W12 <- filter(hsizePre, W==12)
summary(lm(HippocampusDecrease ~ MeanTraumatic, W4))
summary(lm(HippocampusDecrease ~ MeanTraumatic, W8))
summary(lm(HippocampusDecrease ~ MeanTraumatic, W12))
HPre <- a %>%
filter(I == 1 & gamma == 0.8 & Day < -10) %>%
select(MemoryEntropy) %>%
summarise(H=mean(MemoryEntropy)) %>%
as.double()
hsizeA <- a %>%
filter(Day > 49, RuminationFrequency == 0) %>%
group_by(Run, I, PTES, NumAttributes, RuminationFrequency, W, gamma) %>%
summarize(MeanTraumatic = mean(Traumatic),
MeanSimilarity = mean(ChunkSimilarity))
hsizeB <- a %>%
filter(Day < -10, RuminationFrequency == 0) %>%
group_by(Run, I, PTES, NumAttributes, RuminationFrequency, W, gamma) %>%
summarize(H = h_entropy(MemoryEntropy) - HPre,
HippocampusDecrease = 100*(mean(MemoryEntropy)/H1 - 1))
hsizePre <- inner_join(hsizeA, hsizeB)
ggplot(filter(hsizePre, I != 1),
aes(y=MeanTraumatic, x=HippocampusDecrease, col = I)) +
facet_wrap(~ W, scales="free_x", labeller = label_both) +
geom_point(alpha = .1, size=1) +
scale_color_brewer(palette="Dark2") +
geom_smooth(method = "lm", formula = y ~ x, aes(col=I), fill="white",
fullrange= T) + # theme_pander() +
xlab("Percentage Difference in Hippocampus Volume Before PTE") +
ylab("Relative Frequency of Traumatic Memory Intrusion (Day 50-60)") +
ggtitle("Correlation Between Initial Hippocampal Volume \nand Symptom Severity After PTE") +
theme_pander() +
theme(legend.position = "bottom") #+
ggsave("figure5.png")
HPre <- a %>%
filter(I == 1 & gamma == 0.8 & Day < 0) %>%
select(MemoryEntropy) %>%
summarise(H=mean(MemoryEntropy)) %>%
as.double()
hsizeA <- a %>%
filter(Day > 49, RuminationFrequency == 0) %>%
group_by(Run, I, PTES, NumAttributes, RuminationFrequency, W, gamma) %>%
summarize(MeanTraumatic = mean(Traumatic),
MeanSimilarity = mean(ChunkSimilarity))
hsizeB <- a %>%
filter(Day < 0, RuminationFrequency == 0) %>%
group_by(Run, I, PTES, NumAttributes, RuminationFrequency, W, gamma) %>%
summarize(H = h_entropy(MemoryEntropy) - HPre,
HippocampusDecrease = 100*(mean(MemoryEntropy)/H1 - 1))
hsizePre <- inner_join(hsizeA, hsizeB)
HPre <- a %>%
filter(I == 1 & gamma == 0.8 & Day < 0) %>%
select(MemoryEntropy) %>%
summarise(H=mean(MemoryEntropy)) %>%
as.double()
hsizeA <- a %>%
filter(Day > 49, RuminationFrequency == 0) %>%
group_by(Run, I, PTES, NumAttributes, RuminationFrequency, W, gamma) %>%
summarize(MeanTraumatic = mean(Traumatic),
MeanSimilarity = mean(ChunkSimilarity))
hsizeB <- a %>%
filter(Day < 0, RuminationFrequency == 0) %>%
group_by(Run, I, PTES, NumAttributes, RuminationFrequency, W, gamma) %>%
summarize(H = h_entropy(MemoryEntropy) - HPre,
HippocampusDecrease = 100*(mean(MemoryEntropy)/HPre - 1))
hsizePre <- inner_join(hsizeA, hsizeB)
ggplot(filter(hsizePre, I != 1),
aes(y=MeanTraumatic, x=HippocampusDecrease, col = I)) +
facet_wrap(~ W, scales="free_x", labeller = label_both) +
geom_point(alpha = .1, size=1) +
scale_color_brewer(palette="Dark2") +
geom_smooth(method = "lm", formula = y ~ x, aes(col=I), fill="white",
fullrange= T) + # theme_pander() +
xlab("Percentage Difference in Hippocampus Volume Before PTE") +
ylab("Relative Frequency of Traumatic Memory Intrusion (Day 50-60)") +
ggtitle("Correlation Between Initial Hippocampal Volume \nand Symptom Severity After PTE") +
theme_pander() +
theme(legend.position = "bottom") #+
ggsave("figure5.png")
W4 <- filter(hsizePre, W==4)
W8 <- filter(hsizePre, W==8)
W12 <- filter(hsizePre, W==12)
summary(lm(HippocampusDecrease ~ MeanTraumatic, W4))
W4 <- filter(hsizePre, W==4 & I != 1)
W8 <- filter(hsizePre, W==8  & I != 1)
W12 <- filter(hsizePre, W==12  & I != 1)
summary(lm(MeanTraumatic ~ HippocampusDecrease, W4))
summary(lm(MeanTraumatic ~ HippocampusDecrease, W12))
summary(lm(HippocampusDecrease ~ MeanTraumatic, W12))
summary(aov(Traumatic ~ (Day * I),a))
summary(aov(Traumatic ~ (Day * I), filter(a, I>1))
)
summary(aov(Traumatic ~ (Day * I), filter(a, I!=1)))
summary(aov(Traumatic ~ (factor(Day) * I), filter(a, I!=1)))
aov_data <- filter(a, Day > 0, I > 1)
aov_data$Day <- as_factor(aov_data$Day)
summary(aov(Traumatic ~ Day * I), aov_data)) %>%
aov_data <- filter(a, Day > 0, I > 1)
aov_data$Day <- as_factor(aov_data$Day)
summary(aov(Traumatic ~ Day * I), aov_data) %>%
xtable() %>%
kable() %>%
kable_styling(bootstrap_options = c("hover", "striped"))
aov_data <- filter(a, Day > 0, I !=> 1)
aov_data <- filter(a, Day > 0, I != 1)
aov_data$Day <- as_factor(aov_data$Day)
summary(aov(Traumatic ~ Day * I), aov_data) %>%
xtable() %>%
kable() %>%
kable_styling(bootstrap_options = c("hover", "striped"))
aov_data
aov(Traumatic ~ Day * I, aov_data)
a
hsize
summary(aov(HippocampusDecrease ~ I, filter(hsize, I != 1))) %>%
xtable() %>%
kable() %>%
kable_styling(bootstrap_options = c("hover", "striped"))
m <- lm(Traumatic ~ I)
m <- lm(Traumatic ~ I, a)
lm(Traumatic ~ I, a)$residual
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(magrittr)
library(ggplot2)
library(ggthemes)
library(ppcor)
library(reshape2)
#library(gglasso)
library(glmnet)
library(ggsci)
library(viridis)
library(ggExtra)
library(kableExtra)
library(xtable)
#library(data.table)
power2011 <- read_csv("../rsfmri/bin/power_2011.csv",
col_types = cols(ROI=col_double(),
X = col_double(),
Y = col_double(),
Z = col_double(),
Network = col_double(),
Color = col_character(),
NetworkName = col_character())) %>%
dplyr::select(ROI, X, Y, Z, Network, Color, NetworkName)
CREATE_FC = F
if (CREATE_FC) {
for (sub in dir()[grep("sub-*", dir())]) {
roidata <- NULL
for (roi in power2011$ROI) {
network <- power2011 %>%
filter(ROI == roi) %>%
dplyr::select(Network) %>%
as.numeric()
network_name <- power2011 %>%
filter(ROI == roi) %>%
dplyr::select(NetworkName) %>%
as.character()
file_name <- paste("region_",
sprintf("%03d", roi),
"_network_",
sprintf("%02d", max(0, network)),
".txt",
sep="")
#mat <- t(read.table(paste(sub, "func", file_name, sep="/")))
#pc1 <- prcomp(mat)  # PCA
#pc1 <- pc1$x[,1]    # first PC
mat <- colMeans(read.table(paste(sub, "func", file_name, sep="/")))
pc1 <- mat
table <- tibble(subject = sub,
scan = 1:209,
timeseries = pc1,
roi = roi,
network = network,
network_name = network_name)
if (is.null(roidata)) {
roidata <- table
} else {
roidata %<>% bind_rows(table)
}
}
# Pivot long data format into wide data
wroidata <- roidata %>% pivot_wider(id_cols = scan,
names_from = roi,
values_from = timeseries)
X  <- as.matrix(wroidata[,2:265])/1000
PR <- pcor(X)$estimate
R  <- cor(X)
# Generate matrices:
# The partial correlation matrix
long_pr <- melt(PR)
#pdf(paste(sub, "fc_pcorr.pdf", sep="/"))
ggplot(long_pr, aes(x=Var1, y=Var2)) +
geom_raster(aes(fill=value)) +
scale_fill_gradient2(limits=c(-1,1),
low = "blue",
high = "red",
mid = "white") +
theme_pander() +
ggtitle(paste(sub, ": Functional Connectivity (Partial Correlations)", sep="")) +
xlab("ROIs") +
ylab("ROIs")
#dev.off()
ggsave(paste(sub, "fc_pcorr.pdf", sep="/"))
write.table(PR, col.names = T,
row.names = T,
file = paste(sub, "PR.txt", sep="/"))
# The standard correlation matrix
long_r <- melt(R)
#pdf(paste(sub, "fc_corr.pdf", sep="/"))
ggplot(long_r, aes(x=Var1, y=Var2)) +
geom_raster(aes(fill=value)) +
scale_fill_gradient2(limits=c(-1,1), low = "blue", high = "red", mid = "white") +
theme_pander() +
ggtitle(paste(sub, ": Functional Connectivity, Standard Correlations)", sep="")) +
xlab("ROIs") +
ylab("ROIs")
#dev.off()
ggsave(paste(sub, "fc_corr.pdf", sep="/"))
write.table(R, col.names = T,
row.names = T,
file = paste(sub, "R.txt", sep="/"))
}
}
NOFLY <- c()
cols <- outer(power2011$ROI, power2011$ROI, function(x, y) {paste(x, y, sep="-")})
cols %<>% as.vector
connection <- function(x, y) {
paste(min(x, y), max(x, y), sep="-")
}
vconnection <- Vectorize(connection)
Mode <- function(x, na.rm=F) {
if (na.rm) {
x = x[!is.na(x)]
}
ux <- unique(x)
return(ux[which.max(tabulate(match(x, ux)))])
}
reduced_power2011 <- power2011 %>%
dplyr::select(Network, NetworkName) %>%
group_by(Network) %>%
summarize(Network = mean(Network), NetworkName = Mode(NetworkName))
connection_name <- function(x, y) {
first <- min(x, y)
second <- max(x, y)
paste(reduced_power2011 %>% filter(Network == first) %>% dplyr::select(NetworkName) ,
reduced_power2011 %>% filter(Network == second) %>% dplyr::select(NetworkName),
sep="-")
}
vconnection_name <- Vectorize(connection_name)
connection_name2 <- function(x, y) {
first <- min(x, y)
second <- max(x, y)
paste(reduced_power2011$NetworkName[reduced_power2011$Network == first],
reduced_power2011$NetworkName[reduced_power2011$Network == second],
sep="-")
}
vconnection_name2 <- Vectorize(connection_name2)
nets <- outer(power2011$Network, power2011$Network, vconnection)
nets %<>% as.vector
netnames <- outer(power2011$Network, power2011$Network, vconnection_name2)
netnames %<>% as.vector
n <- length(grep("sub-*", dir("../rsfmri/")))
X <- matrix(data = rep(0, length(cols)*n), nrow =  n)
j <- 1
R <- NULL
PR <- NULL
for (sub in dir("../rsfmri/")[grep("sub-*", dir("../rsfmri/"))]) {
M <- read.table(paste("../rsfmri", sub, "PR.txt", sep="/"))
v <- as_vector(M)  # v spreads M column-wise. M is symmetrical, so it should not matter, but better not risk it
#print(c(length(v), mean(v)))
X[j,] <- v
if (length(v[is.na(v)]) > 0) {
print(paste("NA detected in sub", sub))
NOFLY %<>% c(sub)  # Addes sub to NOFLY list
}
j <- j + 1
}
# Create python-compatible data
#
# for (sub in dir()[grep("sub-*", dir())]) {
#   R1 <- read.table(paste(sub, "R.txt", sep="/"))
#   R2 <- read.table(paste(sub, "PR.txt", sep="/"))
#   write.table(R1, paste(sub, "R_py.txt", sep="/"), sep = " ", row.names = F, col.names=F)
#   write.table(R2, paste(sub, "PR_py.txt", sep="/"), sep = " ", row.names = F, col.names=F)
# }
NOI <- c(
#"Uncertain",
# "Sensory/somatomotor Hand",
# "Sensory/somatomotor Mouth",
"Cingulo-opercular Task Control",
# "Auditory",
"Default mode",
"Memory retrieval?",
"Ventral attention",
# "Visual",
"Fronto-parietal Task Control",
#"Salience",
"Subcortical",
#"Cerebellar",
"Dorsal attention"
)
COI <- outer(NOI,
NOI,
function(x, y) {paste(x, y, sep="-")}) %>% as.vector()
# Here we simplify create a tibble which the X columns, and create a censor column to decide which ones to keep
# If ROI1 = i and ROI2 = j, we keep column <i,j> IFF i < j.  This should keep the lower triangle.
censor <- outer(power2011$ROI,
power2011$ROI,
function(x, y) {x < y}) %>% as.vector()
order <- tibble(index = 1:length(nets),
network = nets,
network_names = netnames,
connection = cols,
censor=censor)
order %<>% arrange(network)
I <- order %>%
filter(censor == TRUE) %>%
filter(network_names %in% COI) %>%
dplyr::select(index)
G <- order %>%
filter(censor == TRUE) %>%
filter(network_names %in% COI) %>%
dplyr::select(network)
# G is the real grouping factor for Lasso!
# The real X:
X <- X[,as_vector(I)]
dvs <- read.table("../rsfmri/participants.tsv", sep="\t", header=T)
keep <- !is.na(dvs$Alpha)  & !dvs$Subject %in% NOFLY
Y <- dvs$Alpha[keep]
X <- X[keep,]
dependent <- as_tibble(data.frame(alpha=Y))
#d3 <- pal_d3()
#kol = d3(7)
ggplot(dependent, aes(x=alpha, fill=cut(alpha, 7))) +
geom_histogram(bins=8, col="white", alpha=0.5) +
scale_fill_viridis(option = "plasma", discrete=T) +
geom_vline(xintercept = mean(dependent$alpha)) +
xlab(expression(paste("Rate of Forgetting ", alpha)))+
ylab("Number of Participants") +
ggtitle("Distribution of Rates of Forgetting") +
theme_pander() +
theme(legend.position = "none")
fit <- glmnet(y = Y,
x = X,
alpha=1,
standardize = T
)
fit.cv <- cv.glmnet(y = Y,
x = X,
alpha=1,
standardize=T,
nfolds=length(Y)
)
plot(fit.cv)
plot(fit, sub="Beta Values for Connectivity")
L1norm <- sum(abs(fit$beta[,which(fit$lambda==fit.cv$lambda.min)]))
abline(v=L1norm, lwd=2, lty=2)
lasso_df <- as_tibble(data.frame(lambda=fit.cv$lambda, error=fit.cv$cvm, sd=fit.cv$cvsd))
ggplot(lasso_df, aes(x=lambda, y=error)) +
geom_line(aes(col=error), lwd=2) +
scale_color_viridis(option = "plasma") +
geom_ribbon(aes(ymin=error -sd, ymax=error + sd), alpha=0.2,fill="blue") +
xlab(expression(lambda)) +
ylab("Cross-Validation Error") +
ggtitle(expression(paste(bold("Cross Validation Error Across "), lambda))) +
geom_vline(xintercept = lasso_df$lambda[lasso_df$error==min(lasso_df$error)]) +
theme_pander() +
theme(legend.position="right")
prediction <- predict(object=fit,
newx=X,
s=fit.cv$lambda.min,
type="link")
observed <-tibble(Subject = dvs$Subject[keep],
Alpha=Y,
Condition="Observed")
predicted <- tibble(Subject = dvs$Subject[keep],
Alpha = prediction,
Condition="Predicted")
comparison <- as_tibble(rbind(observed, predicted))
ggplot(comparison, aes(x=reorder(Subject, Alpha), y=Alpha, col=Condition)) +
geom_point(aes(col=Condition), size=4, alpha=0.8) +
geom_line(alpha=0.5, lty=0.2) +
scale_color_d3() +
xlab("Participant")+
ggtitle("Predicted vs. Observed Rates of Forgetting") +
annotate("text", x=20, y=0.35,
label=paste("r(33) =", round(cor(Y, prediction), 3))) +
theme_pander() +
#ylab(expression("Symmetry Span")) +
ylab(expression(paste("Rate of Forgetting ", alpha))) +
theme(axis.text.x = element_text(angle=45, hjust=1, size = 8)) +
theme(legend.position="bottom")
wcomparison <- comparison %>%
pivot_wider(id_cols = c("Subject"), names_from=c("Condition"), values_from=c("Alpha"))
p <- ggplot(wcomparison, aes(y=Predicted, x=Observed, col=(Predicted-Observed)^2)) +
geom_abline(intercept = 0, slope = 1,
col="red",
linetype="dashed") +
geom_point(size=4, alpha=0.6) +
scale_color_viridis("Error", option="plasma", end=0.8) +
theme_pander() +
#  geom_smooth(method="lm") +
theme(legend.position = "right") +
#        legend.  = element_text()) +
#  guides(col=guide_legend("Error")) +
coord_fixed(xlim=c(0.25, 0.4), ylim=c(0.25, 0.4)) +
xlab("Observed Rate of Forgetting") +
ylab("Predicted Rate of Forgetting") +
ggtitle("Predicted vs. Observed\nRates of Forgetting")
ggMarginal(p,
fill="blue", alpha=0.5,
type="density", #bins=13,
col="blue",
margins = "x")
library(tidyverse)
library(kableExtra)
library(xtable)
library(data.table)
library(ggplot2)
library(ggthemes)
library(ggExtra)
library(colorspace)
library(RColorBrewer)
library(gridExtra)
library(ggdendro)
library(viridis)
library(robcor)
source("./code/QEEG_Emotiv_Analysis_Rscript.R")
knitr::opts_chunk$set(echo = TRUE)
behav <- read_tsv("data/behav/behav_data.txt",
col_types=cols())
behav$material[behav$material=="Swahili"] <- "Vocabulary"
behav$material[behav$material=="US Maps"] <- "Maps"
behav <- behav %>% rename(Gender = gender, Age = age)
wbehav <- behav %>% pivot_wider(values_from = alpha,
id_cols = c(Subject, Gender, Age),
names_from = material)
ggplot(data=wbehav, aes(x=Age, col=Gender)) +
geom_histogram(aes(col="white", fill=Gender),
colour="white", alpha=0.5,
position="identity", binwidth = 1) +
scale_color_brewer(palette = "Set1") +
scale_fill_brewer(palette = "Set1") +
ggtitle("Age Distribution by Gender") +
theme_pander()
mu <- behav %>%
group_by(material) %>%
summarize(alpha=mean(alpha))
p1 <- ggplot(behav, aes(x=alpha, fill=material)) +
geom_histogram(col="white", binwidth = 0.025,
alpha=0.5, position="identity") +
scale_color_brewer(palette = "Dark2") +
scale_fill_brewer(palette = "Dark2") +
geom_vline(data=mu, aes(xintercept=alpha, color=material),
linetype="dashed") +
xlab(expression(paste("Estimated value of ", alpha))) +
theme_pander() +
ylab("Count") +
ggtitle("(A) Distribution By Materials") +
theme(legend.position = c(0.2, 0.8)) +
theme(plot.title = element_text(hjust = 0.5))
p2 <- ggplot(wbehav, aes(x=Vocabulary, y=Maps)) +
geom_point(size=4, alpha=0.5, col="black") + #col=K[7]) +
geom_smooth(method = "lm", formula = y ~ x,
col="red", fill="red", fullrange = T, lwd=2) +
theme_pander() +
scale_x_continuous() +
scale_y_continuous() +
ggtitle("(B) Correlation Across Materials") +
xlab(expression(paste(alpha, " Vocabulary"))) +
ylab(expression(paste(alpha, " Maps"))) +
geom_rug(col="black", lwd=1, alpha=.5) +
annotate("segment", x=0.1, y=0.1, xend=0.5,
yend=0.5, col="grey", lwd=1, lty=2) +
theme(plot.title = element_text(hjust = 0.5))
grid.arrange(p1, p2, ncol=2)
ggplot(behav, aes(x=alpha, fill=material)) +
geom_histogram(col="white", binwidth = 0.025,
alpha=0.5, position="identity") +
scale_color_brewer(palette = "Dark2") +
scale_fill_brewer(palette = "Dark2") +
geom_vline(data=mu, aes(xintercept=alpha, color=material),
linetype="dashed") +
xlab(expression(paste("Estimated value of ", alpha))) +
theme_pander() +
ylab("Count") +
ggtitle("Distribution of Rates of Forgetting By Material") +
theme(legend.position = c(0.2, 0.8)) +
theme(plot.title = element_text(hjust = 0.5))
